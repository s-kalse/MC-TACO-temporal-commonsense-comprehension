# -*- coding: utf-8 -*-
"""MC - taco

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iXHVV1vdgzg5Kk-cK2TxP7Nn2mzvqzRq
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import pandas as pd
import numpy as np
import nltk
from nltk import word_tokenize
import string
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, f1_score
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfTransformer

dataframe = pd.read_csv('/content/test_9442.tsv', sep='\t')

def data_preprocessing(df):
  df.columns=['Statement', 'Question', 'Answer', 'Label', 'Category']
  df.dropna(inplace=True)
  enc = LabelEncoder()
  df['Label'] = enc.fit_transform(df['Label'])
  enc2 = LabelEncoder()
  df['Category'] = enc2.fit_transform(df['Category'])
  return df

df = data_preprocessing(dataframe)
print(df.shape)
df.head(5)

df.tail()

def data_cleaning(text):
  remove_punctuation = [i for i in text if i not in string.punctuation]
  remove_punctuation =  ''.join(remove_punctuation)
  return [i for i in str(remove_punctuation).split() if i.lower() not in set(stopwords.words('english'))]

def transformer(df):
  
  stmt_cv = CountVectorizer(analyzer=data_cleaning)
  ques_cv = CountVectorizer(analyzer=data_cleaning)
  ans_cv = CountVectorizer(analyzer=data_cleaning)
  transformer_statement = stmt_cv.fit_transform(df['Statement'])
  transformer_question = ques_cv.fit_transform(df['Question'])
  transformer_answer = ans_cv.fit_transform(df['Answer'])
  return transformer_statement, transformer_question, transformer_answer, stmt_cv, ques_cv, ans_cv

def tfidf_conversion(statement, question, answer):
  tfidf_statement = TfidfTransformer().fit_transform(statement)
  tfidf_question = TfidfTransformer().fit_transform(question)
  tfidf_answer = TfidfTransformer().fit_transform(answer)
  return tfidf_statement, tfidf_question, tfidf_answer

statement, question, answer, stmt_cv, ques_cv, ans_cv = transformer(df)

print(statement.shape)

tfidf_statement, tfidf_question, tfidf_answer = tfidf_conversion(statement, question, answer)

print(tfidf_statement.shape)
print(tfidf_question.shape)
print(tfidf_answer.shape)

def data_merging(tfidf_statement, tfidf_question, tfidf_answer):

  df_statement = pd.DataFrame.sparse.from_spmatrix(tfidf_statement)
  df_question = pd.DataFrame.sparse.from_spmatrix(tfidf_question)
  df_answer = pd.DataFrame.sparse.from_spmatrix(tfidf_answer)
  df1 = pd.concat([df_statement, df_question], axis=1)
  df2 = pd.concat([df1, df_answer], axis=1)
  return df2

df2 = data_merging(tfidf_statement, tfidf_question, tfidf_answer)

df2.shape

def model_building(df2, df):
  X_train, X_test, y_train, y_test = train_test_split(df2, df['Label'], test_size=0.3)
  NBclassifier = MultinomialNB()
  NBclassifier.fit(X_train, y_train)
  predictions = NBclassifier.predict(X_test)
  accuracy = NBclassifier.score(X_test, y_test)
  return predictions, accuracy, confusion_matrix(y_test, predictions), f1_score(y_test, predictions), NBclassifier

predictions, accuracy, conf_matrix, f_score, NBclassifier = model_building(df2, df)

print(accuracy)

print(f_score)

conf_matrix

"""##NEW DATASET"""

new_df = pd.read_csv('/content/dev_3783.tsv', sep='\t')

new_df = data_preprocessing(new_df)



stmt_transform = stmt_cv.transform(new_df['Statement'])

ques_transform = ques_cv.transform(new_df['Question'])

ans_transform = ans_cv.transform(new_df['Answer'])

stmt_tfidf, ques_tfidf, ans_tfidf = tfidf_conversion(stmt_transform, ques_transform, ans_transform)

new_df2 = data_merging(stmt_tfidf, ques_tfidf, ans_tfidf)

pred_2 = NBclassifier.predict(new_df2)

f1_score(pred_2, new_df['Label'])

NBclassifier.score(new_df2, new_df['Label'])

